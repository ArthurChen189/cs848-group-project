{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\furqa\\Desktop\\Masters DS and AI\\Fall 2024\\CS 848\\Project\\Code\\cs848-group-project\\DP_STOA\\PrivSyn\\DataLoader.py:99: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  self.private_data.fillna(self.fillna, inplace=True, downcast = self.datatypes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  marital-status  occupation  relationship  race  \\\n",
       "0    3          1          0               2           1             4     0   \n",
       "1    4          2          0               0           2             3     0   \n",
       "2    3          3          1               1           3             4     0   \n",
       "3    4          3          2               0           3             3     4   \n",
       "4    2          3          0               0           4             1     4   \n",
       "\n",
       "   sex  capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0    1             1             0               4               1       1  \n",
       "1    1             0             0               2               1       1  \n",
       "2    1             0             0               4               1       1  \n",
       "3    1             0             0               4               1       1  \n",
       "4    0             0             0               4               2       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 10, delta: 3e-11, rho: 0.8616407135665874\n",
      "one-way sigma: 8.685474957955632\n",
      "indif sigma: 2.3399999999999998e-09\n",
      "multi-way sigma: 5.838830013637393\n",
      "Iteration 1 of 5 to make the marginals consistent and normalise them\n",
      "Iteration 2 of 5 to make the marginals consistent and normalise them\n",
      "Iteration 3 of 5 to make the marginals consistent and normalise them\n",
      "Iteration 4 of 5 to make the marginals consistent and normalise them\n",
      "Iteration 5 of 5 to make the marginals consistent and normalise them\n",
      "Iteration 1 of 100 completed to consist the marginal views\n",
      "Iteration 2 of 100 completed to consist the marginal views\n",
      "Iteration 3 of 100 completed to consist the marginal views\n",
      "Iteration 4 of 100 completed to consist the marginal views\n",
      "Iteration 5 of 100 completed to consist the marginal views\n",
      "Iteration 6 of 100 completed to consist the marginal views\n",
      "Iteration 7 of 100 completed to consist the marginal views\n",
      "Iteration 8 of 100 completed to consist the marginal views\n",
      "Iteration 9 of 100 completed to consist the marginal views\n",
      "Iteration 10 of 100 completed to consist the marginal views\n",
      "Iteration 11 of 100 completed to consist the marginal views\n",
      "Iteration 12 of 100 completed to consist the marginal views\n",
      "Iteration 13 of 100 completed to consist the marginal views\n",
      "Iteration 14 of 100 completed to consist the marginal views\n",
      "Iteration 15 of 100 completed to consist the marginal views\n",
      "Iteration 16 of 100 completed to consist the marginal views\n",
      "Iteration 17 of 100 completed to consist the marginal views\n",
      "Iteration 18 of 100 completed to consist the marginal views\n",
      "Iteration 19 of 100 completed to consist the marginal views\n",
      "Iteration 20 of 100 completed to consist the marginal views\n",
      "Iteration 21 of 100 completed to consist the marginal views\n",
      "Iteration 22 of 100 completed to consist the marginal views\n",
      "Iteration 23 of 100 completed to consist the marginal views\n",
      "Iteration 24 of 100 completed to consist the marginal views\n",
      "Iteration 25 of 100 completed to consist the marginal views\n",
      "Iteration 26 of 100 completed to consist the marginal views\n",
      "Iteration 27 of 100 completed to consist the marginal views\n",
      "Iteration 28 of 100 completed to consist the marginal views\n",
      "Iteration 29 of 100 completed to consist the marginal views\n",
      "Iteration 30 of 100 completed to consist the marginal views\n",
      "Iteration 31 of 100 completed to consist the marginal views\n",
      "Iteration 32 of 100 completed to consist the marginal views\n",
      "Iteration 33 of 100 completed to consist the marginal views\n",
      "Iteration 34 of 100 completed to consist the marginal views\n",
      "Iteration 35 of 100 completed to consist the marginal views\n",
      "Iteration 36 of 100 completed to consist the marginal views\n",
      "Iteration 37 of 100 completed to consist the marginal views\n",
      "Iteration 38 of 100 completed to consist the marginal views\n",
      "Iteration 39 of 100 completed to consist the marginal views\n",
      "Iteration 40 of 100 completed to consist the marginal views\n",
      "Iteration 41 of 100 completed to consist the marginal views\n",
      "Iteration 42 of 100 completed to consist the marginal views\n",
      "Iteration 43 of 100 completed to consist the marginal views\n",
      "Iteration 44 of 100 completed to consist the marginal views\n",
      "Iteration 45 of 100 completed to consist the marginal views\n",
      "Iteration 46 of 100 completed to consist the marginal views\n",
      "Iteration 47 of 100 completed to consist the marginal views\n",
      "Iteration 48 of 100 completed to consist the marginal views\n",
      "Iteration 49 of 100 completed to consist the marginal views\n",
      "Iteration 50 of 100 completed to consist the marginal views\n",
      "Iteration 51 of 100 completed to consist the marginal views\n",
      "Iteration 52 of 100 completed to consist the marginal views\n",
      "Iteration 53 of 100 completed to consist the marginal views\n",
      "Iteration 54 of 100 completed to consist the marginal views\n",
      "Iteration 55 of 100 completed to consist the marginal views\n",
      "Iteration 56 of 100 completed to consist the marginal views\n",
      "Iteration 57 of 100 completed to consist the marginal views\n",
      "Iteration 58 of 100 completed to consist the marginal views\n",
      "Iteration 59 of 100 completed to consist the marginal views\n",
      "Iteration 60 of 100 completed to consist the marginal views\n",
      "Iteration 61 of 100 completed to consist the marginal views\n",
      "Iteration 62 of 100 completed to consist the marginal views\n",
      "Iteration 63 of 100 completed to consist the marginal views\n",
      "Iteration 64 of 100 completed to consist the marginal views\n",
      "Iteration 65 of 100 completed to consist the marginal views\n",
      "Iteration 66 of 100 completed to consist the marginal views\n",
      "Iteration 67 of 100 completed to consist the marginal views\n",
      "Iteration 68 of 100 completed to consist the marginal views\n",
      "Iteration 69 of 100 completed to consist the marginal views\n",
      "Iteration 70 of 100 completed to consist the marginal views\n",
      "Iteration 71 of 100 completed to consist the marginal views\n",
      "Iteration 72 of 100 completed to consist the marginal views\n",
      "Iteration 73 of 100 completed to consist the marginal views\n",
      "Iteration 74 of 100 completed to consist the marginal views\n",
      "Iteration 75 of 100 completed to consist the marginal views\n",
      "Iteration 76 of 100 completed to consist the marginal views\n",
      "Iteration 77 of 100 completed to consist the marginal views\n",
      "Iteration 78 of 100 completed to consist the marginal views\n",
      "Iteration 79 of 100 completed to consist the marginal views\n",
      "Iteration 80 of 100 completed to consist the marginal views\n",
      "Iteration 81 of 100 completed to consist the marginal views\n",
      "Iteration 82 of 100 completed to consist the marginal views\n",
      "Iteration 83 of 100 completed to consist the marginal views\n",
      "Iteration 84 of 100 completed to consist the marginal views\n",
      "Iteration 85 of 100 completed to consist the marginal views\n",
      "Iteration 86 of 100 completed to consist the marginal views\n",
      "Iteration 87 of 100 completed to consist the marginal views\n",
      "Iteration 88 of 100 completed to consist the marginal views\n",
      "Iteration 89 of 100 completed to consist the marginal views\n",
      "Iteration 90 of 100 completed to consist the marginal views\n",
      "Iteration 91 of 100 completed to consist the marginal views\n",
      "Iteration 92 of 100 completed to consist the marginal views\n",
      "Iteration 93 of 100 completed to consist the marginal views\n",
      "Iteration 94 of 100 completed to consist the marginal views\n",
      "Iteration 95 of 100 completed to consist the marginal views\n",
      "Iteration 96 of 100 completed to consist the marginal views\n",
      "Iteration 97 of 100 completed to consist the marginal views\n",
      "Iteration 98 of 100 completed to consist the marginal views\n",
      "Iteration 99 of 100 completed to consist the marginal views\n",
      "Iteration 100 of 100 completed to consist the marginal views\n",
      "num_rec: 48840\n",
      "attrs: ['age', 'hours-per-week', 'capital-gain', 'capital-loss', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
      "domains: [ 9 11 21 10 10 16  7 16  7  5  2 43  2]\n",
      "Iteration 1 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 2 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 3 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 4 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 5 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 6 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 7 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 8 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 9 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 10 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 11 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 12 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 13 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 14 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 15 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 16 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 17 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 18 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 19 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 20 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 21 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 22 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 23 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 24 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 25 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 26 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 27 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 28 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 29 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 30 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 31 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 32 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 33 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 34 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 35 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 36 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 37 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 38 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 39 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 40 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 41 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 42 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 43 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 44 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 45 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 46 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 47 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 48 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 49 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 50 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 51 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 52 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 53 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 54 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 55 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 56 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 57 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 58 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 59 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 60 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 61 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 62 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 63 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 64 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 65 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 66 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 67 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 68 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 69 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 70 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 71 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 72 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 73 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 74 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 75 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 76 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 77 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 78 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 79 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 80 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 81 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 82 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 83 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 84 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 85 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 86 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 87 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 88 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 89 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 90 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 91 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 92 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 93 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 94 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 95 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 96 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 97 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 98 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 99 of 100 completed to generate the dataset using the noisy marginals\n",
      "Iteration 100 of 100 completed to generate the dataset using the noisy marginals\n"
     ]
    }
   ],
   "source": [
    "# DP-STOA\n",
    "\n",
    "# Importing the necessary modules\n",
    "from DataLoader import DataLoader\n",
    "from Anonymisation import Anonymisation\n",
    "from Consistenter import Consistenter\n",
    "from PostProcessor import RecordPostprocessor\n",
    "from GUM import GraduallyUpdateMethod\n",
    "\n",
    "# Loading the data\n",
    "dl = DataLoader('../datasets/UCIMLAdult/uciml_adult.csv', '../datasets/UCIMLAdult/data.yaml', '../datasets/UCIMLAdult/column_info.json', '../datasets/UCIMLAdult/loading_data.json')\n",
    "dl.data_loader()\n",
    "dl.all_indifs(dl.private_data)\n",
    "\n",
    "# Anonymising the data\n",
    "epsilon = 10\n",
    "delta = 3e-11\n",
    "anon = Anonymisation(epsilon=epsilon,delta=delta)\n",
    "anon.anonymiser(dl)\n",
    "\n",
    "# Consistenting the data\n",
    "cons = Consistenter(anon, dl.all_attrs)\n",
    "cons.make_consistent(iterations = 5)\n",
    "\n",
    "# Synthesising the data\n",
    "gum = GraduallyUpdateMethod(dl, cons)  \n",
    "gum.initialiser(view_iterations = 100)\n",
    "syn_data = gum.synthesize(iterations = 100, num_records = int(cons.num_synthesize_records))\n",
    "\n",
    "# Post-processing the data\n",
    "processor_private = RecordPostprocessor(dl.private_data, dl.configpath, dl.datainfopath, dl.decode_mapping)\n",
    "processor_public = RecordPostprocessor(syn_data, dl.configpath, dl.datainfopath, dl.decode_mapping)\n",
    "original_data = processor_private.post_process()\n",
    "synthesised_dp_stoa_data = processor_public.post_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Adult Dataset MLE Evaluation:\n",
      "Average F1 Score (9 tasks): 0.4230\n",
      "Average R² Score (4 tasks): 0.0913\n",
      "MLE Score: 0.2572\n",
      "\n",
      "Synthesised DP STOA Adult Dataset MLE Evaluation:\n",
      "Average F1 Score (9 tasks): 0.8288\n",
      "Average R² Score (4 tasks): 0.7366\n",
      "MLE Score: 0.7827\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metric Functions\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import  LabelEncoder, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def evaluate_mle(data, categorical_cols=None):\n",
    "    \"\"\"\n",
    "    General MLE score calculation for any dataset\n",
    "    \"\"\"\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = []\n",
    "    \n",
    "    # Prepare features\n",
    "    X = data.copy()\n",
    "    numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = MinMaxScaler()\n",
    "    if numerical_cols:\n",
    "        X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "    \n",
    "    f1_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    # Classification tasks for categorical columns\n",
    "    for target_col in categorical_cols:\n",
    "        # Prepare features\n",
    "        features = X.drop(columns=[target_col])\n",
    "        \n",
    "        # One-hot encode remaining categorical features\n",
    "        cat_cols = [col for col in categorical_cols if col != target_col]\n",
    "        if cat_cols:\n",
    "            features = pd.get_dummies(features, columns=cat_cols)\n",
    "        \n",
    "        # Encode target\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(X[target_col])\n",
    "        \n",
    "        # Split data\n",
    "        split_idx = int(0.8 * len(features))\n",
    "        X_train, X_test = features.iloc[:split_idx], features.iloc[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        # Train classifier\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,  \n",
    "            max_depth=None,    \n",
    "            min_samples_split=2,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "    # Regression tasks for numerical columns\n",
    "    for target_col in numerical_cols:\n",
    "        # Prepare features\n",
    "        features = X.drop(columns=[target_col])\n",
    "        \n",
    "        # One-hot encode categorical features\n",
    "        if categorical_cols:\n",
    "            features = pd.get_dummies(features, columns=categorical_cols)\n",
    "        \n",
    "        y = X[target_col].values\n",
    "        \n",
    "        # Split data\n",
    "        split_idx = int(0.8 * len(features))\n",
    "        X_train, X_test = features.iloc[:split_idx], features.iloc[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        # Train regressor\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    # Calculate final scores\n",
    "    avg_f1 = np.mean(f1_scores) if f1_scores else 0\n",
    "    avg_r2 = np.mean(r2_scores) if r2_scores else 0\n",
    "    mle_score = (avg_f1 + avg_r2) / 2\n",
    "    \n",
    "    print(f\"Average F1 Score ({len(f1_scores)} tasks): {avg_f1:.4f}\")\n",
    "    print(f\"Average R² Score ({len(r2_scores)} tasks): {avg_r2:.4f}\")\n",
    "    print(f\"MLE Score: {mle_score:.4f}\")\n",
    "    \n",
    "    return mle_score\n",
    "\n",
    "# MLE Score for original data\n",
    "print(\"Original Adult Dataset MLE Evaluation:\")\n",
    "mle_score = evaluate_mle(\n",
    "    data=original_data,\n",
    "    categorical_cols=['workclass', 'education', 'marital-status', 'occupation', \n",
    "                     'relationship', 'race', 'sex', 'native-country', 'income']\n",
    ")\n",
    "\n",
    "# MLE Score for synthetic data\n",
    "print(\"\\nSynthesised DP STOA Adult Dataset MLE Evaluation:\")\n",
    "mle_score_synthetic = evaluate_mle(\n",
    "    data=synthesised_dp_stoa_data,\n",
    "    categorical_cols=['workclass', 'education', 'marital-status', 'occupation', \n",
    "                     'relationship', 'race', 'sex', 'native-country', 'income']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
